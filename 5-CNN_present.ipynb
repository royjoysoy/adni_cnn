{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, RandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the table containing participants' information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  IMAGE_ID     Subject   Acq Date                                 Description  \\\n",
      "0   I75150  941_S_1202  8/24/2007    MPR; GradWarp; B1 Correction; N3; Scaled   \n",
      "1  I105437  941_S_1202  2/28/2008    MPR; GradWarp; B1 Correction; N3; Scaled   \n",
      "2   I63874  941_S_1202  1/30/2007  MPR-R; GradWarp; B1 Correction; N3; Scaled   \n",
      "3  I204843  941_S_1202  3/14/2010    MPR; GradWarp; B1 Correction; N3; Scaled   \n",
      "4   I63847  941_S_1194  1/20/2007    MPR; GradWarp; B1 Correction; N3; Scaled   \n",
      "\n",
      "  Visit Group   RID        PTID DX_original         DX    EXAMDATE  Month_bl  \\\n",
      "0   m06    CN  1202  941_S_1202          CN  [1, 0, 0]  2007-08-15   6.03279   \n",
      "1   m12    CN  1202  941_S_1202          CN  [1, 0, 0]  2008-02-25  12.39340   \n",
      "2    sc    CN  1202  941_S_1202          CN  [1, 0, 0]  2007-02-12   0.00000   \n",
      "3   m36    CN  1202  941_S_1202         MCI  [0, 0, 1]  2010-03-10  36.78690   \n",
      "4    sc    CN  1194  941_S_1194          CN  [1, 0, 0]  2007-02-06   0.00000   \n",
      "\n",
      "                                                Path  \n",
      "0  /project_space/ADNI_ROY/derivatives/nii_96/941...  \n",
      "1  /project_space/ADNI_ROY/derivatives/nii_96/941...  \n",
      "2  /project_space/ADNI_ROY/derivatives/nii_96/941...  \n",
      "3  /project_space/ADNI_ROY/derivatives/nii_96/941...  \n",
      "4  /project_space/ADNI_ROY/derivatives/nii_96/941...  \n",
      "--------------- the total images are 1684 ---------------\n",
      "/project_space/ADNI_ROY/derivatives/nii_96/941_S_1202_2007-08-24_S38468_I75150/mris/941_S_1202_2007-08-24_S38468_I75150_orig-in-mni305.nii.gz\n"
     ]
    }
   ],
   "source": [
    "#input_file1 : patients diagnosis\n",
    "table = pd.read_csv('/project_space/ADNI_ROY/scripts/adni_table_all.csv')\n",
    "print(table.head())\n",
    "print('-'*15, 'the total images are', len(table),'-'*15)\n",
    "print(table['Path'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#input_file2: patients images\n",
    "\n",
    "paths = table['Path']\n",
    "\n",
    "# load and viusalize the images\n",
    "for path in paths:\n",
    "    nii_file = nib.load(path)\n",
    "    data = nii_file.get_fdata().transpose((1, 0, 2))\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
    "    for i, slice_num in enumerate(range(30, 71, 10)):\n",
    "        axs[i].imshow(data[:, slice_num, :], cmap='gray')\n",
    "        if i == 0:\n",
    "            axs[i].set_title(f\"sagittal\\n{path.split('/')[-1]} Pitch=({slice_num})\")\n",
    "        else:\n",
    "            axs[i].set_title(f\"Pitch=({slice_num})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuroImagingDataset(Dataset):\n",
    "    def __init__(self, data_df, transform = None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_path = self.data_df.iloc[idx]['Path']\n",
    "        #print(img_path)\n",
    "        label = self.data_df.iloc[idx]['DX_original']\n",
    "        if label == 'CN':\n",
    "            label=torch.tensor([1, 0, 0])\n",
    "        elif label == 'MCI':\n",
    "            label=torch.tensor([0, 0, 1])\n",
    "        elif label == 'Dementia':\n",
    "            label=torch.tensor([0, 1, 0])\n",
    "            \n",
    "        img = nib.load(img_path) \n",
    "        \n",
    "        # get the image data as a numpy array\n",
    "        img = img.get_fdata()\n",
    "        \n",
    "        # convert the image to a tensor and add channel dimension\n",
    "        img =torch.from_numpy(img).unsqueeze(0)\n",
    "      \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            #print('4.self.transform:', img)\n",
    "         #   print(img.shape)\n",
    "        #def image_shape(self):\n",
    "        #    return utils.load_nifti(self.img_path[0]).shape\n",
    "          \n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training, validation and test sets (0.8 : 0.1 : 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the total number of patients is 382\n",
      " the total number of patients' diagnoses is 472 because one patient has multiple diagnoses\n",
      " - CN: 144\n",
      " - MCI: 158\n",
      " - Dementia: 170\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "#patient-wise train-test-split\n",
    "pt_CN = table[table['DX_original'] == 'CN']['PTID'].unique()\n",
    "pt_MCI = table[table['DX_original'] == 'MCI']['PTID'].unique()\n",
    "pt_Dementia = table[table['DX_original'] == 'Dementia']['PTID'].unique()\n",
    "\n",
    "print(f\" the total number of patients is {len(table['PTID'].unique())}\")\n",
    "print(f\" the total number of patients' diagnoses is {len(pt_CN) + len(pt_MCI) +  len(pt_Dementia)} because one patient has multiple diagnoses\")\n",
    "print(f' - CN: {len(pt_CN)}')\n",
    "print(f' - MCI: {len(pt_MCI)}')\n",
    "print(f' - Dementia: {len(pt_Dementia)}')\n",
    "\n",
    "# Use the train_test_split function twice to get 8(train):1(validation):1(test) ratio ##?? should we do filter\n",
    "#1\n",
    "pt_CN_train_val, pt_CN_test = train_test_split(pt_CN, test_size = 0.1, random_state = 0, shuffle = False)\n",
    "pt_MCI_train_val, pt_MCI_test = train_test_split(pt_MCI, test_size = 0.1, random_state = 0, shuffle = False)\n",
    "pt_Dementia_train_val, pt_Dementia_test = train_test_split(pt_Dementia, test_size = 0.1, random_state = 0, shuffle = False)\n",
    "\n",
    "#2\n",
    "pt_CN_train, pt_CN_val = train_test_split(pt_CN_train_val, test_size = 1/9, random_state = 0, shuffle = False)\n",
    "pt_MCI_train, pt_MCI_val = train_test_split(pt_MCI_train_val, test_size = 1/9, random_state = 0, shuffle = False)\n",
    "pt_Dementia_train, pt_Dementia_val = train_test_split(pt_Dementia_train_val, test_size = 1/9,random_state = 0, shuffle = False)\n",
    "\n",
    "# combine train, validation and test sets\n",
    "pt_train = np.concatenate([pt_CN_train, pt_MCI_train, pt_Dementia_train])\n",
    "pt_validation = np.concatenate([pt_CN_val, pt_MCI_val, pt_Dementia_val])\n",
    "pt_test = np.concatenate([pt_CN_test, pt_MCI_test, pt_Dementia_test])\n",
    "#print(pt_train)\n",
    "#print(pt_test)\n",
    "\n",
    "# Because one patient has multiple images\n",
    "train_df = table[table['PTID'].isin(pt_train)]\n",
    "val_df = table[table['PTID'].isin(pt_validation)]\n",
    "test_df = table[table['PTID'].isin(pt_test)]\n",
    "\n",
    "#def has_common_element(list1, list2):\n",
    "#    for element in list1:\n",
    "#        if element in list2:\n",
    "#            print(element)\n",
    "\n",
    "#has_common_element(pt_train, pt_validation)\n",
    "#print('-'*50)\n",
    "#has_common_element(pt_train, pt_test)\n",
    "#print('-'*50)\n",
    "#has_common_element(pt_validation, pt_test)\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#print(val_df['Path'])\n",
    "#print(train_df['Path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an instance of the NeuroImagingDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NeuroImagingDataset at 0x7fa98029c130>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = NeuroImagingDataset(data_df = train_df)\n",
    "validation_dataset = NeuroImagingDataset(data_df = val_df)\n",
    "test_dataset = NeuroImagingDataset(data_df = test_df)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader size: 42\n",
      "Val loader size: 5\n",
      "Test loader size: 5\n",
      "total number: 1664\n"
     ]
    }
   ],
   "source": [
    "# Define the data loaders for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, drop_last = True) # 42*32 = 1344\n",
    "val_loader = DataLoader(validation_dataset, batch_size = 32, drop_last = True) # 5*32 =160\n",
    "test_loader = DataLoader(test_dataset, batch_size  = 32, drop_last = True) # 5*32 = 16\n",
    "# drop the last batch - drop_last =true\n",
    "print(\"Train loader size:\", len(train_loader))\n",
    "print(\"Val loader size:\", len(val_loader))\n",
    "print(\"Test loader size:\", len(test_loader))\n",
    "print('total number:', (len(train_loader) + len(val_loader) + len(test_loader))*32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a convolutional neural network (CNN) model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1,32,3) #kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv3d(32,64,3)#kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size = 2, stride = 2)\n",
    "        self.fc1 = nn.Linear(64*22*22*22, 128)\n",
    "        self.fc2 = nn.Linear(128,3) #final 128 features, 128 nodes\n",
    "        #output vector sized\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        print(\"conv1:\", x.shape)\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        print(\"conv2:\", x.shape)\n",
    "        x = x.view(-1, 64*22*22*22)\n",
    "        print(\"x.view:\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = nn.functional.relu(self.fc1(x))\n",
    "        print(\"x.nn.functional:\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        print(\"fc2:\", x.shape)\n",
    "        x = F.softmax(x, dim = 1) # what does dimension 1 mean?\n",
    "        #softmaxit will reutrn normalized every class oupt the probability of every deimesion added upto 1 \n",
    "        return x\n",
    "\n",
    "# class MyCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MyCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv3d(1,32,1) #kernel_size = 3, stride = 1, padding = 1)\n",
    "#         self.pool1 = nn.MaxPool3d(kernel_size = 2, stride = 2)\n",
    "#         self.conv2 = nn.Conv3d(32,64,1)#kernel_size = 3, stride = 1, padding = 1)\n",
    "#         self.pool2 = nn.MaxPool3d(kernel_size = 2, stride = 2)\n",
    "#         self.conv3 = nn.Conv3d(64,128,1)\n",
    "#         self.fc1 = nn.Linear(128*24*24*24,128)\n",
    "#         self.fc2 = nn.Linear(128,3) #final 128 features, 128 nodes\n",
    "#         #output vector sized\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool1(F.relu(self.conv1(x)))\n",
    "#         print(\"conv1:\", x.shape)\n",
    "#         x = self.pool2(F.relu(self.conv2(x)))\n",
    "#         print(\"conv2:\", x.shape)\n",
    "#         #\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         print(\"conv3:\", x.shape)\n",
    "#         \n",
    "#         x = x.view(-1, 128*24*24*24)\n",
    "#         print(\"x.view:\", x.shape)\n",
    "#         x = nn.functional.relu(self.fc1(x))\n",
    "#         print(\"x.nn.functional:\", x.shape)\n",
    "#         x = self.fc2(x)\n",
    "#         print(\"fc2:\", x.shape)\n",
    "#         x = F.softmax(x, dim = 1) # what does dimension 1 mean?\n",
    "#         #softmaxit will reutrn normalized every class oupt the probability of every deimesion added upto 1 \n",
    "#         return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001) #step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0.7666, 0.1101, 0.1232],\n",
      "        [0.7567, 0.1338, 0.1094],\n",
      "        [0.7180, 0.1139, 0.1681],\n",
      "        [0.6726, 0.1716, 0.1558],\n",
      "        [0.7423, 0.1675, 0.0903],\n",
      "        [0.7628, 0.1490, 0.0882],\n",
      "        [0.7771, 0.1305, 0.0924],\n",
      "        [0.7506, 0.1544, 0.0950],\n",
      "        [0.7655, 0.1212, 0.1133],\n",
      "        [0.8147, 0.0974, 0.0879],\n",
      "        [0.8064, 0.0939, 0.0998],\n",
      "        [0.7779, 0.1062, 0.1159],\n",
      "        [0.7896, 0.0860, 0.1245],\n",
      "        [0.7720, 0.0920, 0.1359],\n",
      "        [0.7555, 0.1068, 0.1377],\n",
      "        [0.7625, 0.1144, 0.1231],\n",
      "        [0.7582, 0.1884, 0.0534],\n",
      "        [0.7069, 0.2232, 0.0698],\n",
      "        [0.7667, 0.1800, 0.0532],\n",
      "        [0.7018, 0.2325, 0.0658],\n",
      "        [0.7472, 0.1997, 0.0530],\n",
      "        [0.7412, 0.1099, 0.1489],\n",
      "        [0.7523, 0.1072, 0.1406],\n",
      "        [0.7163, 0.1181, 0.1656],\n",
      "        [0.6557, 0.1143, 0.2300],\n",
      "        [0.7943, 0.1237, 0.0820],\n",
      "        [0.8124, 0.1126, 0.0750],\n",
      "        [0.8004, 0.1226, 0.0770],\n",
      "        [0.7808, 0.1428, 0.0764],\n",
      "        [0.8018, 0.1157, 0.0825],\n",
      "        [0.8030, 0.1086, 0.0884],\n",
      "        [0.7768, 0.1176, 0.1056]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "conv1: torch.Size([32, 32, 47, 47, 47])\n",
      "conv2: torch.Size([32, 64, 22, 22, 22])\n",
      "x.view: torch.Size([32, 681472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "y_pred tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]], grad_fn=<SoftmaxBackward0>) torch.Size([32, 3])\n",
      "y_true.shape: torch.Size([32, 3])\n",
      "y_true: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.]])\n",
      "Epoch 1 loss: 1.203\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "loss_values = [] #initialize an emptly list to store loss values\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs_x = inputs.float()\n",
    "        #inputs_x = torch.mean(inputs_x, dim=1, keepdim=True)\n",
    "        b, c, d, h, w = inputs_x.shape\n",
    "        #inputs_x = inputs_x.permute(0,1,2,3,4)\n",
    "        outputs = model(inputs_x)\n",
    "        print('y_pred', outputs,outputs.shape)\n",
    "        #labels = labels.float()\n",
    "        labels = labels.float()\n",
    "        #b,c,d,h,w = inputs_x.shape\n",
    "        print('y_true.shape:',labels.shape)\n",
    "        print('y_true:',labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f' % (epoch +1, running_loss / len(train_loader)))\n",
    "    \n",
    "    loss_values.append(running_loss / len(train_loader)) \n",
    "    # append the loss value to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls\n",
    "\n",
    "mvgi##notes\n",
    "# conv1: torch.Size([32, 32, 48, 48, 48]) \n",
    "#     #[batch size, feature, pixel(x), pixel(y), pixel(z)]\n",
    "#     # dimension reduction (pixels 96 -> 48)\n",
    "# conv2: torch.Size([32, 64, 24, 24, 24]) # dimension reduction (pixels 48 -> 24)\n",
    "# conv3: torch.Size([32, 128, 24, 24, 24]) # when last pool we didn't change\n",
    "# x.view: torch.Size([32, 1769472]) # 128*24*24*24\n",
    "# x.nn.functional: torch.Size([32, 128])\n",
    "# fc2: torch.Size([32, 3])\n",
    "# outputs tensor([[0., 0., 1.],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the loss values\n",
    "ax.plot(loss_values)\n",
    "\n",
    "# Set lables and title\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Loss over Epochs')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "Validation loss: 1.233\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Set the model to evaluation mode\n",
    "\n",
    "val_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data\n",
    "        inputs_x = inputs.float()\n",
    "        #inputs_x = torch.mean(inputs_x, dim=1, keepdim=True)\n",
    "        b, c, d, h, w = inputs_x.shape\n",
    "        inputs_x = inputs_x.permute(0,1,2,3,4)\n",
    "        outputs = model(inputs_x)\n",
    "        labels = labels.float()\n",
    "        b,c,d,h,w = inputs_x.shape\n",
    "        val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "print('Validation loss: %.3f' % (val_loss / len(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data\n",
    "        inputs_x = inputs.float()\n",
    "        #inputs_x = torch.mean(inputs_x, dim=1, keepdim=True)\n",
    "        b, c, d, h, w = inputs_x.shape\n",
    "        inputs_x = inputs_x.permute(0,1,2,3,4)\n",
    "        outputs = model(inputs_x)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(predicted)\n",
    "        #total += labels.size(0)\n",
    "        #correct += (predicted == labels).sum().item()\n",
    "\n",
    "#print('Validation accuracy: %.3f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Val. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n",
      "conv1: torch.Size([32, 32, 48, 48, 48])\n",
      "conv2: torch.Size([32, 64, 24, 24, 24])\n",
      "conv3: torch.Size([32, 128, 24, 24, 24])\n",
      "x.view: torch.Size([32, 1769472])\n",
      "x.nn.functional: torch.Size([32, 128])\n",
      "fc2: torch.Size([32, 3])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-46e54fd96029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy of the network on the test images: %d %%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "#%% capture\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        # covert images and lables to Double tensor\n",
    "        images = images.float()\n",
    "        labels = labels.long()\n",
    "        ouputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.sum().item())\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
